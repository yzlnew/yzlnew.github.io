<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>分类器评价指标简析 - Accuracy, Precision, Recall, F1, ROC&AUC - yzlnew</title><link rel=icon type=image/png href=img/favicon.ico><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:title" content="分类器评价指标简析 - Accuracy, Precision, Recall, F1, ROC&AUC"><meta property="og:description" content="在机器学习的模型评估中，选择合适的评价指标很重要。对于回归问题，常常使用一些损失函数，这在各个线上比赛、sklearn 的文档里都能看到。而对于分类或者标注问题，几种常见的指标比较容易混淆，这里简单总结一下。"><meta property="og:type" content="article"><meta property="og:url" content="https://yzlnew.com/2018/05/ml-evaluation/"><meta property="article:published_time" content="2018-05-14T17:18:11+00:00"><meta property="article:modified_time" content="2018-05-14T17:18:11+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="分类器评价指标简析 - Accuracy, Precision, Recall, F1, ROC&AUC"><meta name=twitter:description content="在机器学习的模型评估中，选择合适的评价指标很重要。对于回归问题，常常使用一些损失函数，这在各个线上比赛、sklearn 的文档里都能看到。而对于分类或者标注问题，几种常见的指标比较容易混淆，这里简单总结一下。"><link href="https://fonts.googleapis.com/css?family=Playfair+Display:700" rel=stylesheet type=text/css><link rel=stylesheet type=text/css media=screen href=https://yzlnew.com/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://yzlnew.com/css/main.css><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script><script src=https://yzlnew.com/js/main.js></script></head><body><div class="container wrapper"><div class=header><div class=avatar><a href=https://yzlnew.com/><img src=/img/penrose.webp alt=yzlnew></a></div><h1 class=site-title><a href=https://yzlnew.com/>yzlnew</a></h1><div class=site-description><p>👨‍💻💃</p><nav class="nav social"><ul class=flat><li><a href=yzlnew@gmail.com title=Mail><i data-feather=mail></i></a></li><li><a href=https://github.com/yzlnew title=Github><i data-feather=github></i></a></li><li><a href=https://t.me/r0brew title=Telegram><i data-feather=message-square></i></a></li><li><a href=/index.xml title=RSS><i data-feather=rss></i></a></li></ul></nav></div><nav class=nav><ul class=flat><li><a href=/>Home</a></li><li><a href=/blog>Blog</a></li><li><a href=/life>Life</a></li><li><a href=/about>About</a></li><li><a href=/tags>Tags</a></li></ul></nav></div><div class=post><article><div class=post-header><div class=matter><h1 class=title>分类器评价指标简析 - Accuracy, Precision, Recall, F1, ROC&AUC</h1><div class=meta><span class=date>2018-05-14</span></div></div></div></article><div class=markdown><p>在机器学习的模型评估中，选择合适的评价指标很重要。对于回归问题，常常使用一些损失函数，这在各个线上比赛、sklearn 的文档里都能看到。而对于分类或者标注问题，几种常见的指标比较容易混淆，这里简单总结一下。</p><h3 id=二分类的预测情况>二分类的预测情况</h3><table><thead><tr><th></th><th>预测为正类</th><th>预测为负类</th></tr></thead><tbody><tr><td>实际为正类</td><td>True Positive</td><td>False Negative</td></tr><tr><td>实际为负类</td><td>False Positive</td><td>True Negative</td></tr></tbody></table><p>记忆很简单，前面表示预测是正确（True）的还是错误（False）的，后面表示预测的是正类（Positive）还是负类（Negative），跟英文两组词的原意一致。</p><h3 id=准确率精确率召回率和-f1>准确率、精确率、召回率和 F1</h3><ul><li><p>准确率 Accuracy 即预测正确的样本数占总样本数之比，也就是 0-1 损失函数在测试集上的准确率</p></li><li><p>精确率 Precision 和召回 Recall，对应上表来说，分子都是 TP</p><ul><li>Precision 是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的<strong>查准率</strong>。对于二分类公式如下，即<strong>第一列</strong>中 TP 的占比，预测为正的样本中预测正确的占比。</li></ul><p>$$P = \frac{TP}{TP+FP}$$</p><ul><li>Recall 是指检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的<strong>查全率</strong>。对于二分类公式如下，即<strong>第一行</strong>中 TP 的占比，实际正类中预测正确的占比。</li></ul><p>$$R = \frac{TP}{TP+FN}$$</p><ul><li>F-Measure 是两者的加权调和平均，F1 即 alpha = 1</li></ul><p>$$F = \frac{(\alpha^2+1)P\cdot R}{\alpha^2(P+R)}$$</p><p>很显然一个好的分类器要最大化 P 和 R，但是两者有不可调和的矛盾时，F1 可以作为一个整体的指标。</p><p>然而这几个指标的局限也在于，并不关心分类器在负类上的表现（TN 没有出现过）。所以引出了 ROC 曲线和 AUC。</p></li></ul><h3 id=roc-曲线和-auc>ROC 曲线和 AUC</h3><h4 id=tpr-和-fpr>TPR 和 FPR</h4><ul><li><p>真阳性率 True Positive Rate，在二分类下和 Recall 含义一致，表示<strong>第一行</strong>中的 TP 占比，表示所有正类中预测正确的比例</p><p>$$TPR = \frac{TP}{TP+FN}$$</p></li><li><p>假阳性率 False Positive Rate，弥补了前面指标对于 TN 关注不周的局限，即<strong>第二行</strong>的 FP 占比，表示所有负类中预测错误的比例</p><p>$$FPR = \frac{FP}{FP+TN}$$</p></li></ul><h4 id=roc-曲线>ROC 曲线</h4><p>由上面的两个指标，就能衡量分类器在正类和负类上的表现。而且 TPR 越大越好，FPR 越小越好。ROC（Receiver Operating Characteristic） 曲线就是用来表示两者在阈值变化的情况下的取值变化。</p><p><img src=http://o9gmysn8m.bkt.clouddn.com/20180514152630028191819.png alt></p><p>理解 ROC 曲线其实关键在于曲线是通过遍历所有的阈值得到的。而曲线越靠近左上角，分类器的整体性能越好。但是毕竟是不同的曲线，需要人为判定，为了方便机器判断，引入 AUC。</p><h4 id=auc>AUC</h4><p>AUC 即 Area Under Curve，即 ROC 曲线和 x 轴围成的面积，AUC 越大分类器效果越好。</p><ul><li>AUC = 1，是完美分类器，采用这个预测模型时，不管设定什么阈值都能得出完美预测。绝大多数预测的场合，不存在完美分类器。</li><li>0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</li><li>AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。</li><li>AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。</li></ul><div class="notices info"><p>AUC 的物理意义：假设分类器的输出是样本属于正类的 socre（置信度），则 AUC 的物理意义为，任取一对（正、负）样本，正样本的 score 大于负样本的 score 的概率。</p></div><p>参考资料：</p><ol><li>《统计学习方法》，李航</li><li><a href=http://www.cnblogs.com/maybe2030/p/5375175.html>http://www.cnblogs.com/maybe2030/p/5375175.html</a></li><li><a href=https://zh.wikipedia.org/zh/ROC%E6%9B%B2%E7%BA%BF>https://zh.wikipedia.org/zh/ROC曲线</a></li><li><a href=https://blog.argcv.com/articles/1036.c>https://blog.argcv.com/articles/1036.c</a></li></ol></div><div class=tags><ul class=flat><li><a href=/tags/machine-learning>Machine Learning</a></li></ul></div><div id=gitalk-container></div><link rel=stylesheet href=https://unpkg.com/gitalk/dist/gitalk.css><script src=https://unpkg.com/gitalk/dist/gitalk.min.js></script><script>const gitalk=new Gitalk({clientID:"4ccff83836edce535e3c",clientSecret:"daeca7033b9770d0f062e007477bc4d116499434",repo:"yzlnew.github.io",owner:"yzlnew",admin:["yzlnew"],distractionFreeMode:false,id:location.pathname});(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('gitalk-container').innerHTML='Gitalk comments not available by default when the website is previewed locally.';return;}
gitalk.render('gitalk-container');})();</script></div></div><div class="footer wrapper"><nav class=nav><div>2018 © Copyright @yzlnew | <a href=https://github.com/knadh/hugo-ink>Ink</a> theme on <a href=https://gohugo.io>Hugo</a></div></nav></div><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-61197619-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script>feather.replace()</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body);></script></body></html>